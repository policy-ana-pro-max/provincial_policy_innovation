{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41f3b1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "355990it [00:14, 25332.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import random\n",
    "import jieba\n",
    "import hanlp\n",
    "import time\n",
    "import pandas as pd\n",
    "#import torch\n",
    "import openpyxl\n",
    "#from torch import cosine_similarity\n",
    "\n",
    "#from text2vec import SentenceModel, cos_sim, semantic_search\n",
    "from datetime import datetime\n",
    "#从自写工具包中导入：修饰词判定、修饰词查找\n",
    "from utils import modifier_judge, modifier_search\n",
    "\n",
    "#device = torch.device('cuda')\n",
    "#use_gpu = torch.cuda.is_available()\n",
    "\n",
    "def read_vectors(path, topn):  # read top n word vectors, i.e. top is 10000\n",
    "    lines_num, dim = 0, 0\n",
    "    vectors = {}\n",
    "    iw = []\n",
    "    wi = {}\n",
    "    #num_file = sum([1 for i in open(path, encoding='utf-8', errors='ignore')])  \n",
    "    #print(num_file)\n",
    "    with open(path, encoding='utf-8', errors='ignore') as f:\n",
    "        first_line = True\n",
    "        for line in tqdm(f):\n",
    "            if first_line:\n",
    "                first_line = False\n",
    "                dim = int(line.rstrip().split()[1])\n",
    "                continue\n",
    "            lines_num += 1\n",
    "            tokens = line.rstrip().split(' ')\n",
    "            vectors[tokens[0]] = np.expand_dims(np.asarray([float(x) for x in tokens[1:]]),axis=0)\n",
    "            #vectors[tokens[0]] = torch.tensor([float(x) for x in tokens[1:]], device=device).unsqueeze(0)\n",
    "            iw.append(tokens[0])\n",
    "            if topn != 0 and lines_num >= topn:\n",
    "                break\n",
    "    for i, w in enumerate(iw):\n",
    "        wi[w] = i\n",
    "    return vectors, iw, wi, dim\n",
    "\n",
    "vectors_path = \"../test/sgns.renmin.bigram\"\n",
    "topn = 0\n",
    "vectors, iw, wi, dim = read_vectors(vectors_path, topn) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e5154f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n",
      "000\n",
      "-0.5\n"
     ]
    }
   ],
   "source": [
    "def cos_sim(vec1, vec2):\n",
    "    if vec1.all() == 0 or vec2.all() == 0:\n",
    "        return np.zeros([1])[0]\n",
    "    else:\n",
    "        return (vec1.dot(vec2[0]) / (np.linalg.norm(vec1[0]) * np.linalg.norm(vec2[0])))[0]\n",
    "\n",
    "\n",
    "\n",
    "def word2vec(word1):\n",
    "    if word1 in vectors:\n",
    "        return vectors[word1]\n",
    "    else:\n",
    "        #print('not find')\n",
    "        first_line = True\n",
    "        for character in word1:\n",
    "            if first_line:\n",
    "                first_line = False\n",
    "                if character in vectors:\n",
    "                    vector = vectors[character]\n",
    "                else: \n",
    "                    vector = np.zeros([1, 300])\n",
    "                continue\n",
    "            if character in vectors:\n",
    "                vector = np.append(vector,vectors[character], axis = 0)\n",
    "        return np.mean(vector, axis = 0).reshape(1,300)\n",
    "\n",
    "def words2vec(word_list):\n",
    "    first_line = True\n",
    "    for word in word_list:\n",
    "        if first_line:\n",
    "            first_line = False\n",
    "            vector = word2vec(word)\n",
    "            continue\n",
    "        vector =  np.append(vector,word2vec(word), axis = 0)\n",
    "    return np.mean(vector, axis = 0).reshape(1,300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d07231c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_phrases(path):\n",
    "    with open (path, 'r',  encoding='utf-8') as phrases_read:\n",
    "        phrases = []\n",
    "        first_line = True\n",
    "        for line in phrases_read:\n",
    "            if first_line:\n",
    "                first_line = False\n",
    "                line_number = line\n",
    "                continue\n",
    "            cut = line.replace('\\n', '').split('。')\n",
    "            phrase = cut[0].split(',')\n",
    "            sentence = cut[1]+' '+cut[2]\n",
    "            phrase = [tuple(x.split(';')) for x in phrase]\n",
    "            phrase.append(sentence)\n",
    "            phrases.append(tuple(phrase))\n",
    "    return phrases, line_number\n",
    "\n",
    "\n",
    "def simlirity_for_phase_mode1(phase_before, phase_now):\n",
    "    #print(phase_before, phase_now)\n",
    "    sim_v = cos_sim(word2vec(phase_before[0]),word2vec(phase_now[0]))\n",
    "    sim_key = cos_sim(word2vec(phase_before[1]),word2vec(phase_now[1]))\n",
    "    sim_modify = np.zeros([1])[0]\n",
    "    if len(phase_now)>2:\n",
    "        if len(phase_before)>2:\n",
    "            for word_now in phase_now[2:]:\n",
    "                sim_modify_tem = np.zeros([1])[0]\n",
    "                for word_before in phase_before[2:]:\n",
    "                    tem_sim = cos_sim(word2vec(word_before),word2vec(word_now))\n",
    "                    if tem_sim > sim_modify_tem:\n",
    "                        sim_modify_tem = tem_sim\n",
    "                sim_modify = sim_modify + sim_modify_tem\n",
    "            sim_modify = sim_modify/len(phase_now[2:])\n",
    "            return 0.1*sim_v+0.5*sim_key+0.4*sim_modify\n",
    "        else:\n",
    "            return 0.1*sim_v+0.6*sim_key\n",
    "    else:\n",
    "        return 0.14*sim_v+0.86*sim_key\n",
    "    \n",
    "def simlirity_for_phase_mode2(phase_before, phase_now):\n",
    "    sim_key = cos_sim(word2vec(phase_before[0]),word2vec(phase_now[0]))\n",
    "    sim_modify = np.zeros([1])[0]\n",
    "    if len(phase_now)>1:\n",
    "        if len(phase_before)>1:\n",
    "            sim_modify = cos_sim(words2vec(phase_before[1:]),words2vec(phase_now[1:]))\n",
    "            return 0.4*sim_key+0.6*sim_modify\n",
    "        else:\n",
    "            return 0.4*sim_key\n",
    "    else:\n",
    "        return sim_key\n",
    "\n",
    "def simlirity_for_phrases(phrases_before, phrases_now):\n",
    "    sum1 = np.zeros([1])[0]\n",
    "    sum2 = np.zeros([1])[0]\n",
    "    count1 = len(phrases_now[0])\n",
    "    count2 = len(phrases_now[1])\n",
    "    another_mode = False\n",
    "    if len(phrases_now[1])> len(phrases_before[1]):\n",
    "        another_mode = True\n",
    "    temp_phrases_now = [list(i_now) for i_now in phrases_now]\n",
    "    temp_phrases_before = [list(i_before) for i_before in phrases_before]\n",
    "    #print(phrases_before, phrases_now)\n",
    "    #print(temp_phrases_before, temp_phrases_now)\n",
    "    if phrases_now[0][0] and phrases_now[1][0]:\n",
    "        the_type = True\n",
    "    else:\n",
    "        the_type = False\n",
    "    #现在的无mode2，过去无mode2\n",
    "    #print(phrases_before, phrases_now)\n",
    "    #print(phrases_before[1][0], phrases_now[1])\n",
    "    while temp_phrases_now[0][0] and temp_phrases_before[0][0]:\n",
    "        sim1_2 = np.zeros([1])[0]\n",
    "        for index1_1, phrase_now in enumerate(temp_phrases_now[0]):            \n",
    "            for index1_2, phrase_before in enumerate(temp_phrases_before[0]):\n",
    "                sim_temp1 = simlirity_for_phase_mode1(phrase_before.split(' '), phrase_now.split(' '))\n",
    "                #print(sim_temp1)\n",
    "                if sim_temp1 > sim1_2:\n",
    "                    pos1_1 = phrase_now\n",
    "                    pos1_2 = phrase_before\n",
    "                    sim1_2 = sim_temp1\n",
    "        sum1 = sum1 + sim1_2\n",
    "        if len(temp_phrases_now[0]) == 1 or len(temp_phrases_before[0]) == 1:\n",
    "            break\n",
    "        temp_phrases_now[0].remove(pos1_1)\n",
    "        temp_phrases_before[0].remove(pos1_2)\n",
    "    \n",
    "    while temp_phrases_now[1][0] and temp_phrases_before[1][0]:\n",
    "        sim2_2 = np.zeros([1])[0]-0.5\n",
    "        pos2_1 = ''\n",
    "        pos2_2 = ''\n",
    "        for index2_1, phrase_now2 in enumerate(temp_phrases_now[1]):\n",
    "            for index2_2, phrase_before2 in enumerate(temp_phrases_before[1]):\n",
    "                sim_temp2 = simlirity_for_phase_mode2(phrase_before2.split(' '), phrase_now2.split(' '))\n",
    "                if sim_temp2 > sim2_2:\n",
    "                    pos2_1 = phrase_now2\n",
    "                    pos2_2 = phrase_before2\n",
    "                    sim2_2 = sim_temp2\n",
    "        sum2 = sum2 + sim2_2\n",
    "        if len(temp_phrases_now[1]) == 1 or len(temp_phrases_before[1]) == 1:\n",
    "            if another_mode and pos2_1 in temp_phrases_now[1]:\n",
    "                temp_phrases_now[1].remove(pos2_1)\n",
    "            break\n",
    "        try:\n",
    "            temp_phrases_now[1].remove(pos2_1)\n",
    "            temp_phrases_before[1].remove(pos2_2)\n",
    "        except:\n",
    "            print(phrases_before, phrases_now)\n",
    "            print(temp_phrases_before, temp_phrases_now, pos2_1, pos2_2)\n",
    "            break\n",
    "            \n",
    "    if another_mode:\n",
    "        while temp_phrases_now[1][0] and temp_phrases_before[0][0]:\n",
    "            sim2_3 = np.zeros([1])[0]\n",
    "            for index23_1, phrase_now23 in enumerate(temp_phrases_now[1]):\n",
    "                for index23_2, phrase_before23 in enumerate(temp_phrases_before[0]):\n",
    "                    sim_temp23 = simlirity_for_phase_mode2(phrase_before23.split(' ')[1:], phrase_now23.split(' '))\n",
    "                    if sim_temp23 > sim2_3:\n",
    "                        pos23_1 = phrase_now23\n",
    "                        pos23_2 = phrase_before23\n",
    "                        sim2_3 = sim_temp23\n",
    "            sum2 = sum2 + sim2_3\n",
    "            if len(temp_phrases_now[1]) == 1 or len(temp_phrases_before[0]) == 1:\n",
    "                break\n",
    "            try:\n",
    "                temp_phrases_now[1].remove(pos23_1)\n",
    "            except:\n",
    "                print(phrases_before, phrases_now)\n",
    "                print(temp_phrases_before, temp_phrases_now, pos23_1, pos23_2)\n",
    "                break\n",
    "    \n",
    "    if count1 > 0 :\n",
    "        sim1 = sum1/count1\n",
    "    if count2 > 0 :\n",
    "        sim2 = sum2/count2\n",
    "    \n",
    "    if the_type:\n",
    "        return 0.77*sim1 + 0.23*sim2\n",
    "    else:\n",
    "        return sim1 + sim2\n",
    "        \n",
    "        \n",
    "def similirity_for_corpus(corpus_before, corpus_now):\n",
    "    inno_dict={ \"α=0.88\":[], \"α=0.9\":[]}\n",
    "    sim_dict={ \"α=0.88\":[], \"α=0.9\":[]}\n",
    "    defussion_dict = {\"α=0.88\":[], \"α=0.9\":[]}\n",
    "    dire_dict = {\"α=0.88\":[], \"α=0.9\":[]}\n",
    "    count_list = []\n",
    "\n",
    "    for line_now in corpus_now:\n",
    "     \n",
    "        sim_dot88 = 0\n",
    "        dot88 =True\n",
    "        defu_dot88 = 'null'\n",
    "        dir_dot88 = 'null'        \n",
    "        sim_dot9 = 0\n",
    "        dot9 =True\n",
    "        defu_dot9 = 'null'\n",
    "        dir_dot9 = 'null'        \n",
    "\n",
    "        for line_before in corpus_before:\n",
    "            common_elements = list(set(line_before[1][0].split(' ')).intersection(line_now[1][0].split(' ')))\n",
    "            #print(line_now[-1]+' '+line_before[-1])\n",
    "            if common_elements:\n",
    "                temp_sim_dot = simlirity_for_phrases(line_before[2:-1], line_now[2:-1])\n",
    "             \n",
    "                if dot88:\n",
    "                    if temp_sim_dot > sim_dot88:                            \n",
    "                        sim_dot88 = temp_sim_dot\n",
    "                        defu_dot88 = line_before[-1]+' '+line_now[-1]\n",
    "                        dir_dot88 = line_before[0][0]+','+line_now[0][0]\n",
    "                        if sim_dot88 >= 0.88:\n",
    "                            dot88 = False\n",
    "                if dot9:\n",
    "                    if temp_sim_dot > sim_dot9:                            \n",
    "                        sim_dot9 = temp_sim_dot\n",
    "                        defu_dot9 = line_before[-1]+' '+line_now[-1]\n",
    "                        dir_dot9 = line_before[0][0]+','+line_now[0][0]\n",
    "                        if sim_dot9 >= 0.9:\n",
    "                            dot9 = False                     \n",
    "                            break\n",
    "        \n",
    "        if dot88 or dot9:\n",
    "            for line_this in count_list:\n",
    "                common_this_elements = list(set(line_this[1][0].split(' ')).intersection(line_now[1][0].split(' ')))\n",
    "                if common_this_elements:\n",
    "                    temp_this_sim_dot = simlirity_for_phrases(line_this[2:-1], line_now[2:-1])\n",
    "                    if dot88:\n",
    "                        if temp_this_sim_dot > sim_dot88:\n",
    "                            sim_dot88 = temp_this_sim_dot\n",
    "                            defu_dot88 = line_this[-1]+' '+line_now[-1]\n",
    "                            dir_dot88 = line_this[0][0]+','+line_now[0][0]\n",
    "                            if sim_dot88 >= 0.88:\n",
    "                                dot88 = False \n",
    "\n",
    "                    if dot9:\n",
    "                        if temp_this_sim_dot > sim_dot9:                            \n",
    "                            sim_dot9 = temp_this_sim_dot\n",
    "                            defu_dot9 = line_this[-1]+' '+line_now[-1]\n",
    "                            dir_dot9 = line_this[0][0]+','+line_now[0][0]\n",
    "                            if sim_dot9 >= 0.9:\n",
    "                                dot9 = False                     \n",
    "                                break\n",
    "                                \n",
    "        if sim_dot88 < 0.88:\n",
    "            count_list.append(tuple(line_now))\n",
    "            inno_dict[\"α=0.88\"].append(line_now)\n",
    "        \n",
    "        sim_dict[\"α=0.88\"].append(sim_dot88)\n",
    "        defussion_dict[\"α=0.88\"].append(defu_dot88)\n",
    "        dire_dict[\"α=0.88\"].append(dir_dot88)\n",
    "        \n",
    "        if sim_dot9 < 0.9:\n",
    "            inno_dict[\"α=0.9\"].append(line_now)\n",
    "        sim_dict[\"α=0.9\"].append(sim_dot9)\n",
    "        defussion_dict[\"α=0.9\"].append(defu_dot9)\n",
    "        dire_dict[\"α=0.9\"].append(dir_dot9)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return sim_dict,defussion_dict, dire_dict, inno_dict, count_list\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4be12820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['安徽省', '山西省', '福建省', '上海市', '陕西省', '广西壮族自治区', '宁夏回族自治区', '重庆市', '浙江省', '贵州省', '湖北省', '湖南省', '青海省', '黑龙江省', '河北省', '河南省', '江西省', '天津市', '国务院', '辽宁省', '江苏省', '新疆维吾尔自治区', '山东省', '甘肃省', '四川省', '海南省', '内蒙古自治区', '北京市', '云南省', '西藏自治区', '吉林省', '广东省']\n"
     ]
    }
   ],
   "source": [
    "province_list = os.listdir('../data/pre_processed')\n",
    "#province_list.remove('.DS_Store')\n",
    "#file_name_list.remove('国务院')\n",
    "print(province_list)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b1491a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "安徽省 1998\n",
      "709\n",
      "安徽省 1999\n",
      "1301\n",
      "安徽省 2000\n",
      "1844\n",
      "安徽省 2001\n",
      "2218\n",
      "安徽省 2002\n",
      "2579\n",
      "安徽省 2003\n",
      "2885\n",
      "安徽省 2004\n",
      "3313\n",
      "安徽省 2005\n",
      "3683\n",
      "安徽省 2006\n",
      "12819\n"
     ]
    }
   ],
   "source": [
    "#1119，该这里了\n",
    "for province in province_list[0:2]:\n",
    "    first_time = True\n",
    "    denominator_selfCorpus = []\n",
    "    #for year in time_list[1:]:\n",
    "    for time_year in range(1998,2025):  \n",
    "        save_path = \"../data/sig_reports/\"+province+str(time_year)+\"年政府工作报告.txt\"\n",
    "        if os.path.exists(save_path):\n",
    "            selfCorpus, num =read_phrases(save_path)\n",
    "            #if first_time:\n",
    "             #   first_time = False\n",
    "            #    denominator_selfCorpus.extend(selfCorpus)\n",
    "             #   continue\n",
    "            print(province, time_year)\n",
    "            simi_list,def_list, dir_list, inno_list,count_list = similirity_for_corpus(denominator_selfCorpus, selfCorpus)\n",
    "            denominator_selfCorpus.extend(count_list)\n",
    "            print(len(denominator_selfCorpus))\n",
    "            for alpha in [\"α=0.88\"]: \n",
    "                data_dict = {\"sim\": simi_list[alpha], \"sentences\": def_list[alpha], \"from\":dir_list[alpha]}\n",
    "                df = pd.DataFrame(data_dict)\n",
    "                excel_path = \"../results/adoption_judge/\"+province+str(time_year)+\"年政府工作报告_self_similarity.xlsx\"\n",
    "                df.to_excel(excel_path,index=False)\n",
    "\n",
    "                with open(file =\"../results/adoptions/\"+province+str(time_year)+\"年政府工作报告_self_similarity.txt\", mode='w',encoding='utf - 8') as f_forward:\n",
    "                    f_forward.write('innovation_num:  '+str(len(inno_list[alpha]))+num+'\\n')\n",
    "                    for every_line in inno_list[alpha]:\n",
    "                        f_forward.write(every_line[0][0]+',')\n",
    "                        f_forward.write(every_line[1][0]+',')\n",
    "                        for index_mode1_phrase, mode1_phrase in enumerate(every_line[2]):\n",
    "                            for index_mode1_word, mode1_word in enumerate(mode1_phrase):\n",
    "                                f_forward.write(mode1_word)\n",
    "                            if index_mode1_phrase< len(every_line[2])-1:\n",
    "                                f_forward.write(';')\n",
    "                        f_forward.write(',')\n",
    "                        for index_mode2_phrase, mode2_phrase in enumerate(every_line[3]):\n",
    "                            for index_mode2_word, mode2_word in enumerate(mode2_phrase):\n",
    "                                f_forward.write(mode2_word)\n",
    "                            if index_mode2_phrase< len(every_line[3])-1:\n",
    "                                f_forward.write(';') \n",
    "                        f_forward.write('。')\n",
    "                        f_forward.write(every_line[4])\n",
    "                        f_forward.write('\\n')"
   ]
  }
