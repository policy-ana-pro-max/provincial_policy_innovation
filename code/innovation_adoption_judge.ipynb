{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41f3b1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "355990it [00:14, 25332.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import random\n",
    "import jieba\n",
    "import hanlp\n",
    "import time\n",
    "import pandas as pd\n",
    "#import torch\n",
    "import openpyxl\n",
    "#from torch import cosine_similarity\n",
    "\n",
    "#from text2vec import SentenceModel, cos_sim, semantic_search\n",
    "from datetime import datetime\n",
    "#从自写工具包中导入：修饰词判定、修饰词查找\n",
    "from utils import modifier_judge, modifier_search\n",
    "\n",
    "#device = torch.device('cuda')\n",
    "#use_gpu = torch.cuda.is_available()\n",
    "\n",
    "def read_vectors(path, topn):  # read top n word vectors, i.e. top is 10000\n",
    "    lines_num, dim = 0, 0\n",
    "    vectors = {}\n",
    "    iw = []\n",
    "    wi = {}\n",
    "    #num_file = sum([1 for i in open(path, encoding='utf-8', errors='ignore')])  \n",
    "    #print(num_file)\n",
    "    with open(path, encoding='utf-8', errors='ignore') as f:\n",
    "        first_line = True\n",
    "        for line in tqdm(f):\n",
    "            if first_line:\n",
    "                first_line = False\n",
    "                dim = int(line.rstrip().split()[1])\n",
    "                continue\n",
    "            lines_num += 1\n",
    "            tokens = line.rstrip().split(' ')\n",
    "            vectors[tokens[0]] = np.expand_dims(np.asarray([float(x) for x in tokens[1:]]),axis=0)\n",
    "            #vectors[tokens[0]] = torch.tensor([float(x) for x in tokens[1:]], device=device).unsqueeze(0)\n",
    "            iw.append(tokens[0])\n",
    "            if topn != 0 and lines_num >= topn:\n",
    "                break\n",
    "    for i, w in enumerate(iw):\n",
    "        wi[w] = i\n",
    "    return vectors, iw, wi, dim\n",
    "\n",
    "#Use your pre-trained file and put it in data/pre_trained_vactors\n",
    "vectors_path = \"../data/pre-trained_vectors/sgns.renmin.bigram\"\n",
    "topn = 0\n",
    "vectors, iw, wi, dim = read_vectors(vectors_path, topn) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e5154f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n",
      "000\n",
      "-0.5\n"
     ]
    }
   ],
   "source": [
    "def cos_sim(vec1, vec2):\n",
    "    if vec1.all() == 0 or vec2.all() == 0:\n",
    "        return np.zeros([1])[0]\n",
    "    else:\n",
    "        return (vec1.dot(vec2[0]) / (np.linalg.norm(vec1[0]) * np.linalg.norm(vec2[0])))[0]\n",
    "\n",
    "\n",
    "\n",
    "def word2vec(word1):\n",
    "    if word1 in vectors:\n",
    "        return vectors[word1]\n",
    "    else:\n",
    "        #print('not find')\n",
    "        first_line = True\n",
    "        for character in word1:\n",
    "            if first_line:\n",
    "                first_line = False\n",
    "                if character in vectors:\n",
    "                    vector = vectors[character]\n",
    "                else: \n",
    "                    vector = np.zeros([1, 300])\n",
    "                continue\n",
    "            if character in vectors:\n",
    "                vector = np.append(vector,vectors[character], axis = 0)\n",
    "        return np.mean(vector, axis = 0).reshape(1,300)\n",
    "\n",
    "def words2vec(word_list):\n",
    "    first_line = True\n",
    "    for word in word_list:\n",
    "        if first_line:\n",
    "            first_line = False\n",
    "            vector = word2vec(word)\n",
    "            continue\n",
    "        vector =  np.append(vector,word2vec(word), axis = 0)\n",
    "    return np.mean(vector, axis = 0).reshape(1,300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d07231c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_phrases(path):\n",
    "    with open (path, 'r',  encoding='utf-8') as phrases_read:\n",
    "        phrases = []\n",
    "        first_line = True\n",
    "        for line in phrases_read:\n",
    "            if first_line:\n",
    "                first_line = False\n",
    "                line_number = line\n",
    "                continue\n",
    "            cut = line.replace('\\n', '').split('。')\n",
    "            phrase = cut[0].split(',')\n",
    "            sentence = cut[1]+' '+cut[2]\n",
    "            phrase = [tuple(x.split(';')) for x in phrase]\n",
    "            phrase.append(sentence)\n",
    "            phrases.append(tuple(phrase))\n",
    "    return phrases, line_number\n",
    "\n",
    "\n",
    "def simlirity_for_phase_mode1(phase_before, phase_now):\n",
    "    #print(phase_before, phase_now)\n",
    "    sim_v = cos_sim(word2vec(phase_before[0]),word2vec(phase_now[0]))\n",
    "    sim_key = cos_sim(word2vec(phase_before[1]),word2vec(phase_now[1]))\n",
    "    sim_modify = np.zeros([1])[0]\n",
    "    if len(phase_now)>2:\n",
    "        if len(phase_before)>2:\n",
    "            for word_now in phase_now[2:]:\n",
    "                sim_modify_tem = np.zeros([1])[0]\n",
    "                for word_before in phase_before[2:]:\n",
    "                    tem_sim = cos_sim(word2vec(word_before),word2vec(word_now))\n",
    "                    if tem_sim > sim_modify_tem:\n",
    "                        sim_modify_tem = tem_sim\n",
    "                sim_modify = sim_modify + sim_modify_tem\n",
    "            sim_modify = sim_modify/len(phase_now[2:])\n",
    "            return 0.1*sim_v+0.5*sim_key+0.4*sim_modify\n",
    "        else:\n",
    "            return 0.1*sim_v+0.6*sim_key\n",
    "    else:\n",
    "        return 0.14*sim_v+0.86*sim_key\n",
    "    \n",
    "def simlirity_for_phase_mode2(phase_before, phase_now):\n",
    "    sim_key = cos_sim(word2vec(phase_before[0]),word2vec(phase_now[0]))\n",
    "    sim_modify = np.zeros([1])[0]\n",
    "    if len(phase_now)>1:\n",
    "        if len(phase_before)>1:\n",
    "            sim_modify = cos_sim(words2vec(phase_before[1:]),words2vec(phase_now[1:]))\n",
    "            return 0.4*sim_key+0.6*sim_modify\n",
    "        else:\n",
    "            return 0.4*sim_key\n",
    "    else:\n",
    "        return sim_key\n",
    "\n",
    "def simlirity_for_phrases(phrases_before, phrases_now):\n",
    "    sum1 = np.zeros([1])[0]\n",
    "    sum2 = np.zeros([1])[0]\n",
    "    count1 = len(phrases_now[0])\n",
    "    count2 = len(phrases_now[1])\n",
    "    another_mode = False\n",
    "    if len(phrases_now[1])> len(phrases_before[1]):\n",
    "        another_mode = True\n",
    "    temp_phrases_now = [list(i_now) for i_now in phrases_now]\n",
    "    temp_phrases_before = [list(i_before) for i_before in phrases_before]\n",
    "    #print(phrases_before, phrases_now)\n",
    "    #print(temp_phrases_before, temp_phrases_now)\n",
    "    if phrases_now[0][0] and phrases_now[1][0]:\n",
    "        the_type = True\n",
    "    else:\n",
    "        the_type = False\n",
    "    #现在的无mode2，过去无mode2\n",
    "    #print(phrases_before, phrases_now)\n",
    "    #print(phrases_before[1][0], phrases_now[1])\n",
    "    while temp_phrases_now[0][0] and temp_phrases_before[0][0]:\n",
    "        sim1_2 = np.zeros([1])[0]\n",
    "        for index1_1, phrase_now in enumerate(temp_phrases_now[0]):            \n",
    "            for index1_2, phrase_before in enumerate(temp_phrases_before[0]):\n",
    "                sim_temp1 = simlirity_for_phase_mode1(phrase_before.split(' '), phrase_now.split(' '))\n",
    "                #print(sim_temp1)\n",
    "                if sim_temp1 > sim1_2:\n",
    "                    pos1_1 = phrase_now\n",
    "                    pos1_2 = phrase_before\n",
    "                    sim1_2 = sim_temp1\n",
    "        sum1 = sum1 + sim1_2\n",
    "        if len(temp_phrases_now[0]) == 1 or len(temp_phrases_before[0]) == 1:\n",
    "            break\n",
    "        temp_phrases_now[0].remove(pos1_1)\n",
    "        temp_phrases_before[0].remove(pos1_2)\n",
    "    \n",
    "    while temp_phrases_now[1][0] and temp_phrases_before[1][0]:\n",
    "        sim2_2 = np.zeros([1])[0]-0.5\n",
    "        pos2_1 = ''\n",
    "        pos2_2 = ''\n",
    "        for index2_1, phrase_now2 in enumerate(temp_phrases_now[1]):\n",
    "            for index2_2, phrase_before2 in enumerate(temp_phrases_before[1]):\n",
    "                sim_temp2 = simlirity_for_phase_mode2(phrase_before2.split(' '), phrase_now2.split(' '))\n",
    "                if sim_temp2 > sim2_2:\n",
    "                    pos2_1 = phrase_now2\n",
    "                    pos2_2 = phrase_before2\n",
    "                    sim2_2 = sim_temp2\n",
    "        sum2 = sum2 + sim2_2\n",
    "        if len(temp_phrases_now[1]) == 1 or len(temp_phrases_before[1]) == 1:\n",
    "            if another_mode and pos2_1 in temp_phrases_now[1]:\n",
    "                temp_phrases_now[1].remove(pos2_1)\n",
    "            break\n",
    "        try:\n",
    "            temp_phrases_now[1].remove(pos2_1)\n",
    "            temp_phrases_before[1].remove(pos2_2)\n",
    "        except:\n",
    "            print(phrases_before, phrases_now)\n",
    "            print(temp_phrases_before, temp_phrases_now, pos2_1, pos2_2)\n",
    "            break\n",
    "            \n",
    "    if another_mode:\n",
    "        while temp_phrases_now[1][0] and temp_phrases_before[0][0]:\n",
    "            sim2_3 = np.zeros([1])[0]\n",
    "            for index23_1, phrase_now23 in enumerate(temp_phrases_now[1]):\n",
    "                for index23_2, phrase_before23 in enumerate(temp_phrases_before[0]):\n",
    "                    sim_temp23 = simlirity_for_phase_mode2(phrase_before23.split(' ')[1:], phrase_now23.split(' '))\n",
    "                    if sim_temp23 > sim2_3:\n",
    "                        pos23_1 = phrase_now23\n",
    "                        pos23_2 = phrase_before23\n",
    "                        sim2_3 = sim_temp23\n",
    "            sum2 = sum2 + sim2_3\n",
    "            if len(temp_phrases_now[1]) == 1 or len(temp_phrases_before[0]) == 1:\n",
    "                break\n",
    "            try:\n",
    "                temp_phrases_now[1].remove(pos23_1)\n",
    "            except:\n",
    "                print(phrases_before, phrases_now)\n",
    "                print(temp_phrases_before, temp_phrases_now, pos23_1, pos23_2)\n",
    "                break\n",
    "    \n",
    "    if count1 > 0 :\n",
    "        sim1 = sum1/count1\n",
    "    if count2 > 0 :\n",
    "        sim2 = sum2/count2\n",
    "    \n",
    "    if the_type:\n",
    "        return 0.77*sim1 + 0.23*sim2\n",
    "    else:\n",
    "        return sim1 + sim2\n",
    "        \n",
    "        \n",
    "def similirity_for_corpus(corpus_before, corpus_now):\n",
    "    inno_dict={ \"α=0.88\":[], \"α=0.9\":[]}\n",
    "    sim_dict={ \"α=0.88\":[], \"α=0.9\":[]}\n",
    "    defussion_dict = {\"α=0.88\":[], \"α=0.9\":[]}\n",
    "    dire_dict = {\"α=0.88\":[], \"α=0.9\":[]}\n",
    "    count_list = []\n",
    "\n",
    "    for line_now in corpus_now:\n",
    "     \n",
    "        sim_dot88 = 0\n",
    "        dot88 =True\n",
    "        defu_dot88 = 'null'\n",
    "        dir_dot88 = 'null'        \n",
    "        sim_dot9 = 0\n",
    "        dot9 =True\n",
    "        defu_dot9 = 'null'\n",
    "        dir_dot9 = 'null'        \n",
    "\n",
    "        for line_before in corpus_before:\n",
    "            common_elements = list(set(line_before[1][0].split(' ')).intersection(line_now[1][0].split(' ')))\n",
    "            #print(line_now[-1]+' '+line_before[-1])\n",
    "            if common_elements:\n",
    "                temp_sim_dot = simlirity_for_phrases(line_before[2:-1], line_now[2:-1])\n",
    "             \n",
    "                if dot88:\n",
    "                    if temp_sim_dot > sim_dot88:                            \n",
    "                        sim_dot88 = temp_sim_dot\n",
    "                        defu_dot88 = line_before[-1]+' '+line_now[-1]\n",
    "                        dir_dot88 = line_before[0][0]+','+line_now[0][0]\n",
    "                        if sim_dot88 >= 0.88:\n",
    "                            dot88 = False\n",
    "                if dot9:\n",
    "                    if temp_sim_dot > sim_dot9:                            \n",
    "                        sim_dot9 = temp_sim_dot\n",
    "                        defu_dot9 = line_before[-1]+' '+line_now[-1]\n",
    "                        dir_dot9 = line_before[0][0]+','+line_now[0][0]\n",
    "                        if sim_dot9 >= 0.9:\n",
    "                            dot9 = False                     \n",
    "                            break\n",
    "        \n",
    "        if dot88 or dot9:\n",
    "            for line_this in count_list:\n",
    "                common_this_elements = list(set(line_this[1][0].split(' ')).intersection(line_now[1][0].split(' ')))\n",
    "                if common_this_elements:\n",
    "                    temp_this_sim_dot = simlirity_for_phrases(line_this[2:-1], line_now[2:-1])\n",
    "                    if dot88:\n",
    "                        if temp_this_sim_dot > sim_dot88:\n",
    "                            sim_dot88 = temp_this_sim_dot\n",
    "                            defu_dot88 = line_this[-1]+' '+line_now[-1]\n",
    "                            dir_dot88 = line_this[0][0]+','+line_now[0][0]\n",
    "                            if sim_dot88 >= 0.88:\n",
    "                                dot88 = False \n",
    "\n",
    "                    if dot9:\n",
    "                        if temp_this_sim_dot > sim_dot9:                            \n",
    "                            sim_dot9 = temp_this_sim_dot\n",
    "                            defu_dot9 = line_this[-1]+' '+line_now[-1]\n",
    "                            dir_dot9 = line_this[0][0]+','+line_now[0][0]\n",
    "                            if sim_dot9 >= 0.9:\n",
    "                                dot9 = False                     \n",
    "                                break\n",
    "                                \n",
    "        if sim_dot88 < 0.88:\n",
    "            count_list.append(tuple(line_now))\n",
    "            inno_dict[\"α=0.88\"].append(line_now)\n",
    "        \n",
    "        sim_dict[\"α=0.88\"].append(sim_dot88)\n",
    "        defussion_dict[\"α=0.88\"].append(defu_dot88)\n",
    "        dire_dict[\"α=0.88\"].append(dir_dot88)\n",
    "        \n",
    "        if sim_dot9 < 0.9:\n",
    "            inno_dict[\"α=0.9\"].append(line_now)\n",
    "        sim_dict[\"α=0.9\"].append(sim_dot9)\n",
    "        defussion_dict[\"α=0.9\"].append(defu_dot9)\n",
    "        dire_dict[\"α=0.9\"].append(dir_dot9)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return sim_dict,defussion_dict, dire_dict, inno_dict, count_list\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4be12820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['安徽省', '山西省', '福建省', '上海市', '陕西省', '广西壮族自治区', '宁夏回族自治区', '重庆市', '浙江省', '贵州省', '湖北省', '湖南省', '青海省', '黑龙江省', '河北省', '河南省', '江西省', '天津市', '国务院', '辽宁省', '江苏省', '新疆维吾尔自治区', '山东省', '甘肃省', '四川省', '海南省', '内蒙古自治区', '北京市', '云南省', '西藏自治区', '吉林省', '广东省']\n"
     ]
    }
   ],
   "source": [
    "province_list = os.listdir('../data/pre_processed')\n",
    "#province_list.remove('.DS_Store')\n",
    "#file_name_list.remove('国务院')\n",
    "print(province_list)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b1491a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "安徽省 1998\n",
      "709\n",
      "安徽省 1999\n",
      "1301\n",
      "563\n",
      "山西省 1999\n",
      "1092\n",
      "山西省 2000\n",
      "1525\n",
      "山西省 2001\n",
      "2012\n",
      "山西省 2002\n",
      "2476\n",
      "山西省 2003\n",
      "2898\n",
      "山西省 2004\n",
      "3445\n",
      "山西省 2005\n",
      "3839\n",
      "山西省 2006\n",
      "4317\n",
      "山西省 2007\n",
      "4754\n",
      "山西省 2008\n",
      "5216\n",
      "山西省 2009\n",
      "5703\n",
      "山西省 2010\n",
      "6034\n",
      "山西省 2011\n",
      "6372\n",
      "山西省 2012\n",
      "6663\n",
      "山西省 2013\n",
      "6979\n",
      "山西省 2014\n",
      "7348\n",
      "山西省 2015\n",
      "7713\n",
      "山西省 2016\n",
      "8135\n",
      "山西省 2017\n",
      "8858\n",
      "山西省 2018\n",
      "9506\n",
      "山西省 2019\n",
      "10070\n",
      "山西省 2020\n",
      "10629\n",
      "山西省 2021\n",
      "11138\n",
      "山西省 2022\n",
      "11647\n",
      "山西省 2023\n",
      "12319\n",
      "山西省 2024\n",
      "12819\n"
     ]
    }
   ],
   "source": [
    "#1119，该这里了\n",
    "for province in province_list[0:2]:\n",
    "    first_time = True\n",
    "    denominator_selfCorpus = []\n",
    "    #for year in time_list[1:]:\n",
    "    for time_year in range(1998,2025):  \n",
    "        save_path = \"../data/sig_reports/\"+province+str(time_year)+\"年政府工作报告.txt\"\n",
    "        if os.path.exists(save_path):\n",
    "            selfCorpus, num =read_phrases(save_path)\n",
    "            #if first_time:\n",
    "             #   first_time = False\n",
    "            #    denominator_selfCorpus.extend(selfCorpus)\n",
    "             #   continue\n",
    "            print(province, time_year)\n",
    "            simi_list,def_list, dir_list, inno_list,count_list = similirity_for_corpus(denominator_selfCorpus, selfCorpus)\n",
    "            denominator_selfCorpus.extend(count_list)\n",
    "            print(len(denominator_selfCorpus))\n",
    "            for alpha in [\"α=0.88\"]: \n",
    "                data_dict = {\"sim\": simi_list[alpha], \"sentences\": def_list[alpha], \"from\":dir_list[alpha]}\n",
    "                df = pd.DataFrame(data_dict)\n",
    "                excel_path = \"../data/adoption_judge/\"+province+str(time_year)+\"年政府工作报告_self_similarity.xlsx\"\n",
    "                df.to_excel(excel_path,index=False)\n",
    "\n",
    "                with open(file =\"../data/adoptions/\"+province+str(time_year)+\"年政府工作报告_self_similarity.txt\", mode='w',encoding='utf - 8') as f_forward:\n",
    "                    f_forward.write('innovation_num:  '+str(len(inno_list[alpha]))+num+'\\n')\n",
    "                    for every_line in inno_list[alpha]:\n",
    "                        f_forward.write(every_line[0][0]+',')\n",
    "                        f_forward.write(every_line[1][0]+',')\n",
    "                        for index_mode1_phrase, mode1_phrase in enumerate(every_line[2]):\n",
    "                            for index_mode1_word, mode1_word in enumerate(mode1_phrase):\n",
    "                                f_forward.write(mode1_word)\n",
    "                            if index_mode1_phrase< len(every_line[2])-1:\n",
    "                                f_forward.write(';')\n",
    "                        f_forward.write(',')\n",
    "                        for index_mode2_phrase, mode2_phrase in enumerate(every_line[3]):\n",
    "                            for index_mode2_word, mode2_word in enumerate(mode2_phrase):\n",
    "                                f_forward.write(mode2_word)\n",
    "                            if index_mode2_phrase< len(every_line[3])-1:\n",
    "                                f_forward.write(';') \n",
    "                        f_forward.write('。')\n",
    "                        f_forward.write(every_line[4])\n",
    "                        f_forward.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bee94257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "强高技能人才队伍建设 努力培养和壮大党政人才队伍 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_Annotation_auto = pd.read_excel('../中国地方政府工作报告数据库/地级市政府工作报告/preprocessed_data/df_Annotation.xlsx', index_col=0)\n",
    "for index, row in df_Annotation_auto.iterrows():\n",
    "    s1 = row['sentence1']\n",
    "    s2 = row['sentence2']\n",
    "    label = row['label']\n",
    "    break\n",
    "print(s1, s2, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5bb6e4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**这一标注正确。**\n",
      "\n",
      "### 分析如下：\n",
      "\n",
      "- **sentence1**: “强高技能人才队伍建设”  \n",
      "  → 宾语是“高技能人才队伍”，动词是“强”（即“加强”），修饰词为“高技能”。\n",
      "\n",
      "- **sentence2**: “努力培养和壮大党政人才队伍”  \n",
      "  → 宾语是“党政人才队伍”，动词为“培养和壮大”，修饰词为“党政”。\n",
      "\n",
      "### 原则分析：\n",
      "\n",
      "- **原则1（宾语为核心）：**\n",
      "  - sentence1 的宾语是“高技能人才队伍”，强调的是技术性强、操作层面的人才；\n",
      "  - sentence2 的宾语是“党政人才队伍”，强调的是政府机关、党务管理方面的人才。\n",
      "  - 两者在宾语的含义上差异明显，指向完全不同类别的“人才队伍”。\n",
      "\n",
      "- **原则3（是否为子集关系）：**\n",
      "  - sentence2 并不是 sentence1 的扩展或包含，二者内容不重叠，不存在子集关系。\n",
      "\n",
      "- **原则4（不可比时默认为创新）：**\n",
      "  - 两句话内容和对象有本质区别，不具备直接延续性，属于不同政策方向。\n",
      "\n",
      "- **原则5（字数与核心词问题）：**\n",
      "  - 不适用，因为sentence2并没有在表达上缩减，且其核心概念“党政人才队伍”与sentence1的“高技能人才队伍”不属于同一范畴。\n",
      "\n",
      "### 结论：\n",
      "\n",
      "由于两个句子所指的政策对象完全不同（一个是“高技能人才”，一个是“党政人才”），因此 sentence2 相对于 sentence1 是具有创新性的政策举措。\n",
      "\n",
      "✅ **这一标注正确（label=1）**\n",
      "这一标注错误。\n",
      "\n",
      "**分析过程：**\n",
      "\n",
      "根据原则1，政策举措的**宾语**是判断创新性的最关键因素。  \n",
      "- sentence1的宾语是“党政人才队伍”，强调的是**党政领域的人才培养和壮大**；\n",
      "- sentence2的宾语是“高技能人才队伍”，强调的是**具有高技能的专业人才队伍建设**。\n",
      "\n",
      "两者宾语在内容和指向上有明显差异，分别聚焦于不同的群体：“党政人才” vs “高技能人才”。因此，sentence2在宾语上与sentence1有实质性不同，不是其子集，也不是其延续或扩展。\n",
      "\n",
      "再依据原则3，只有当前一句子的含义是后一句子的一部分时，才可以判断为创新；而这里两句之间没有包含关系。\n",
      "\n",
      "因此，sentence2相对于sentence1并不是创新，而是提出了一个**新的、独立的政策方向**。原label标注为1（即判断为创新）是不准确的。\n",
      "\n",
      "**结论：这一标注错误。**\n",
      "这一标注错误。\n",
      "\n",
      "**分析如下：**\n",
      "\n",
      "- **sentence1:** 努力培养和壮大高技能人才  \n",
      "- **sentence2:** 加强高技能人才队伍建设  \n",
      "- **label:** 0（表示判断为“非创新”）\n",
      "\n",
      "### 根据五项原则进行判断：\n",
      "\n",
      "#### 原则1：\n",
      "- 两个句子的宾语核心是“高技能人才”，虽然表述略有不同，但含义基本一致。\n",
      "- sentence1强调的是“培养和壮大”，即发展数量和能力；\n",
      "- sentence2强调的是“加强……建设”，更偏向于系统性地推进该群体的发展。\n",
      "\n",
      "两者在宾语上没有实质性扩展或变化，都围绕“高技能人才”。\n",
      "\n",
      "#### 原则2：\n",
      "- 动词部分“努力培养和壮大” vs “加强……建设”，动词表达方式不同，但根据原则2，动词不影响创新性判断。\n",
      "\n",
      "#### 原则3：\n",
      "- 没有出现并列结构或内容包含关系，因此不适用。\n",
      "\n",
      "#### 原则4：\n",
      "- 句子内容具有可比性，不属于完全不同的结构或内容，因此不适用。\n",
      "\n",
      "#### 原则5：\n",
      "- sentence2字数略少于sentence1，但并未丢失关键信息，“高技能人才”仍是核心内容，符合原则5中关于“核心单词被前句包含”的情况。\n",
      "\n",
      "### 结论：\n",
      "两个句子在政策举措的核心内容（宾语）上没有实质差异，仅在表达方式（动词短语）上有细微差别。根据原则2和原则5，这种情况下应判定sentence2相对于sentence1为**非创新**，即**label=0 是正确的**。\n",
      "\n",
      "---\n",
      "\n",
      "但是，由于用户指出“如果某条记录的`label`标注为1但实际上应该是0，或者`label`标注为0但实际上应该是1，这些都属于错误判断”，而我们的分析认为**label=0是正确的**，所以：\n",
      "\n",
      "> **这一标注正确。**\n",
      "这一标注错误。\n",
      "\n",
      "**理由：**\n",
      "\n",
      "根据你的描述和五项原则，我们来分析这两个句子：\n",
      "\n",
      "- **sentence1**: 加强高技能人才队伍建设  \n",
      "- **sentence2**: 努力培养和壮大高技能人才  \n",
      "- **label**: 0（表示判断为“非创新”）\n",
      "\n",
      "### 分析：\n",
      "\n",
      "#### 原则1：宾语是核心\n",
      "- sentence1 的宾语是：“高技能人才队伍建设”\n",
      "- sentence2 的宾语是：“高技能人才”\n",
      "\n",
      "虽然两者都围绕“高技能人才”，但 sentence1 中的“队伍建设”强调的是一个组织化、系统化的构建过程，而 sentence2 更宽泛地讲“培养和壮大高技能人才”。\n",
      "\n",
      "“队伍建设”是一个结构性、组织性的概念，具有更明确的政策含义；而“壮大人才”较为抽象，不涉及组织结构层面的内容。\n",
      "\n",
      "所以从宾语角度看，sentence1 包含了比 sentence2 更具体的内容（即组织建设），而 sentence2 并未包含这些内容。\n",
      "\n",
      "#### 原则3：子集关系判断创新性\n",
      "sentence2 所指的“培养和壮大高技能人才”可以视为一个较广泛的目标，而 sentence1 的“加强队伍建设”则是实现该目标的一种具体手段。\n",
      "\n",
      "因此，sentence2 相对于 sentence1 来说，并不是其上位概念或扩展内容，反而是更泛化的内容。这意味着 sentence2 并没有比 sentence1 提供更多政策举措上的新意或增量信息。\n",
      "\n",
      "#### 原则5：字数与核心词覆盖\n",
      "sentence2 比 sentence1 字数少，且核心词汇“高技能人才”被 sentence1 完全覆盖。sentence1 多出“队伍”“建设”两个关键词，这是 sentence2 没有的具体内容。\n",
      "\n",
      "根据原则5，这种情况下 sentence2 应判断为非创新。\n",
      "\n",
      "---\n",
      "\n",
      "### 结论：\n",
      "尽管 label 标注为 0（非创新），但实际上 sentence2 相对于 sentence1 是**非创新**，标注应为 0，符合实际判断。\n",
      "\n",
      "但这里存在理解问题：原句中 sentence1 更具体，sentence2 更泛化，sentence2 并未提供新的政策内容，因此它确实不是创新。\n",
      "\n",
      "所以最终结论是：\n",
      "\n",
      "**这一标注正确。**\n",
      "\n",
      "（注意：此处修正了最初的观点，因为经过逐条分析发现 sentence2 确实不是创新）\n",
      "这一标注错误。\n",
      "\n",
      "**分析如下：**\n",
      "\n",
      "- **sentence1**: 努力培养和壮大企业经营管理人才队伍  \n",
      "- **sentence2**: 加强经营管理人才队伍建设  \n",
      "- **label**: 0（即判断sentence2相对于sentence1是非创新）\n",
      "\n",
      "根据五项判断原则：\n",
      "\n",
      "---\n",
      "\n",
      "### **原则1：宾语最重要**\n",
      "\n",
      "- sentence1的宾语是“**企业经营管理人才队伍**”，强调的是企业的经营管理人才。\n",
      "- sentence2的宾语是“**经营管理人才队伍**”，范围更广，不再局限于“企业”。\n",
      "\n",
      "虽然“企业经营管理人才”可以看作是“经营管理人才”的一个子集，但sentence2所涵盖的对象还包括非企业的经营管理人才（如事业单位、政府机构等），因此其**宾语含义有所扩展**，具有一定的**外延扩大**。\n",
      "\n",
      "因此，sentence2在宾语上具有**超出sentence1的内容**，属于**创新性变化**。\n",
      "\n",
      "---\n",
      "\n",
      "### **原则3：子集关系**\n",
      "\n",
      "sentence1强调的是“企业”中的经营管理人才，而sentence2则泛指“经营管理人才”，sentence1的内容可视为sentence2的一个**子集**。\n",
      "\n",
      "根据原则3，这种情况下，sentence2相对于sentence1应被判断为**创新（label=1）**。\n",
      "\n",
      "---\n",
      "\n",
      "### **原则5：字数与核心词**\n",
      "\n",
      "sentence2比sentence1简略，但并没有出现核心词被完全包含且意义缩小的情况。相反，“加强……队伍建设”是对“努力培养和壮大……人才队伍”的一种拓展表达，并未丢失关键信息，反而扩大了适用范围。\n",
      "\n",
      "因此不构成非创新的理由。\n",
      "\n",
      "---\n",
      "\n",
      "### **结论**\n",
      "\n",
      "sentence2在政策指向的范围上**大于**sentence1，具有明确的外延扩展，符合创新性的标准。\n",
      "\n",
      "所以，**原标注label=0是错误的**，应为**label=1**。\n",
      "\n",
      "---\n",
      "\n",
      "**最终结论：这一标注错误**\n",
      "这一标注错误。\n",
      "\n",
      "**理由如下：**\n",
      "\n",
      "根据原则1，政策句子的核心在于宾语。我们来比较两个句子的宾语部分：\n",
      "\n",
      "- sentence1的宾语是：“经营管理人才队伍建设”\n",
      "- sentence2的宾语是：“企业经营管理人才队伍”\n",
      "\n",
      "虽然表述略有不同，但核心宾语都是“经营管理人才队伍”，sentence2只是在修饰上增加了“企业”二字，而“壮大”与“加强”在动词层面不影响判断（依据原则2）。\n",
      "\n",
      "此外，sentence2表达的内容并没有显著超出sentence1的范围，也没有新增并列内容或实质性扩展。因此，sentence2相对于sentence1**不是创新**，即label应为0。\n",
      "\n",
      "**结论：这一标注错误。**\n",
      "这一标注错误。\n",
      "\n",
      "**理由如下：**\n",
      "\n",
      "根据**原则5**：\n",
      "\n",
      "- sentence1: “努力培养和壮大农村实用人才队伍”\n",
      "- sentence2: “加强农村实用人才队伍建设”\n",
      "\n",
      "对比两个句子：\n",
      "\n",
      "- sentence2的表达虽然动词不同（“加强”vs“努力培养和壮大”），但**核心宾语是相同的**：“农村实用人才队伍建设”与“农村实用人才队伍”实质含义一致，后者可视为前者的自然结果或组成部分。\n",
      "- sentence2明显比sentence1**字数更少**，且其核心词汇“加强”、“农村实用人才队伍”都被sentence1包含或涵盖（“努力培养和壮大”涵盖了“加强”的含义）。\n",
      "\n",
      "因此，根据原则5，**sentence2相对于sentence1不是创新**，label为0是**正确的判断**。\n",
      "\n",
      "---\n",
      "\n",
      "然而，我们再仔细看给出的 label 是 **0**，即判断sentence2相对于sentence1是非创新。这个判断**实际上是正确的**，因为sentence2是对sentence1的简化表达，没有实质性扩展或改变政策内容。\n",
      "\n",
      "所以最终结论应为：\n",
      "\n",
      "✅ **这一标注正确**\n",
      "这一标注错误。\n",
      "\n",
      "**分析过程：**\n",
      "\n",
      "根据原则5，如果后一个句子的字数明显少于前一个句子，且核心单词都被前一个句子包含，那么后一个句子相对于前一个句子不是创新。例如：\n",
      "\n",
      "- sentence1: 加强农村实用人才队伍建设；\n",
      "- sentence2: 加强人才队伍建设。\n",
      "\n",
      "这种情况属于非创新，因为“农村实用人才队伍”是“人才队伍”的子集，后者更宽泛，但核心内容被前者覆盖。\n",
      "\n",
      "然而，在本例中：\n",
      "\n",
      "- sentence1: 加强农村实用人才队伍建设；\n",
      "- sentence2: 努力培养和壮大农村实用人才队伍。\n",
      "\n",
      "虽然两个句子的动词不同（“加强” vs “努力培养和壮大”），但根据**原则2**，动词不影响创新性判断。关键在于宾语。\n",
      "\n",
      "- sentence1 的宾语是“农村实用人才队伍建设”；\n",
      "- sentence2 的宾语是“农村实用人才队伍”。\n",
      "\n",
      "从语义上看，“农村实用人才队伍”是“农村实用人才队伍建设”中的核心组成部分。sentence2强调的是“队伍”的“培养和壮大”，而sentence1强调的是“队伍建设”。虽然表述略有不同，但它们描述的核心对象一致，即“农村实用人才队伍”。\n",
      "\n",
      "因此，sentence2并没有在政策举措的实质内容上增加新的宾语或扩大范围，也没有引入并列结构来扩展政策内涵，因此不能被视为“创新”。\n",
      "\n",
      "**结论：label 应为 0（非创新）**，所以原标注 label:0 是正确的。\n",
      "\n",
      "### 最终结论：**这一标注正确**\n",
      "这一标注错误。\n",
      "\n",
      "**理由如下：**\n",
      "\n",
      "根据原则1，句子的**宾语**是判断创新性的核心。我们来对比两个句子的宾语：\n",
      "\n",
      "- sentence1: 努力培养和壮大**专业技术人才**\n",
      "- sentence2: 加强**专业技术人才队伍建设**\n",
      "\n",
      "虽然两句话的动词不同（“努力培养和壮大” vs “加强”），但根据**原则2**，动词不影响创新性判断。\n",
      "\n",
      "关键在于宾语：\n",
      "- sentence1 的宾语是“专业技术人才”\n",
      "- sentence2 的宾语是“专业技术人才队伍建设”\n",
      "\n",
      "“队伍建设”是对“人才”的进一步具体化或拓展，意味着不仅关注个体人才的培养，还强调组织结构、体系化的建设。因此，sentence2 的内容在政策含义上比 sentence1 更广，具有**新的政策维度**。\n",
      "\n",
      "根据**原则3**，如果后一句的内容包含前一句未明确提及的新内容，则属于创新。这里，“队伍建设”可以视为对“人才培养和壮大”的扩展与深化，因此 sentence2 相对于 sentence1 是**创新**。\n",
      "\n",
      "### 结论：\n",
      "label 应为 **1**，而原标注为 **0**，因此**这一标注错误**。\n",
      "这一标注错误。\n",
      "\n",
      "**分析如下：**\n",
      "\n",
      "- **sentence1**: 加强专业技术人才队伍建设  \n",
      "- **sentence2**: 努力培养和壮大专业技术人才  \n",
      "- **label**: 0（表示非创新）\n",
      "\n",
      "### 应用判断原则：\n",
      "\n",
      "#### 原则1：\n",
      "- **宾语是判断的核心。**\n",
      "  - sentence1的宾语是“专业技术人才队伍建设”；\n",
      "  - sentence2的宾语是“专业技术人才”。\n",
      "\n",
      "两者宾语虽然相似，但**不是完全等同**。“队伍建设”强调的是组织结构、体系上的建设，而“培养和壮大”更偏向个体数量和能力的提升，二者在政策含义上有**明显差异**，属于不同维度的举措。\n",
      "\n",
      "#### 原则3：\n",
      "- 如果sentence1的内容是sentence2的子集或范围更窄，则sentence2为创新。\n",
      "- 在此，“加强队伍建设”可以看作是“培养和壮大人才”的一种具体方式，而“培养和壮大”所涵盖的范围可能更广（包括教育、引进、激励等多个方面），因此sentence2比sentence1更宽泛、更具拓展性。\n",
      "\n",
      "#### 原则5不适用：\n",
      "- 句子长度相近，且sentence2并未简单地省略修饰词，而是改变了宾语的重点。\n",
      "\n",
      "### 结论：\n",
      "由于两个句子在宾语表达上存在实质性差异，且sentence2提出的内容具有新的政策指向，因此**sentence2相对于sentence1是创新的**。\n",
      "\n",
      "所以，正确的label应为**1**，而非原标注的**0**。\n",
      "\n",
      "> **最终结论：这一标注错误**\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "\n",
    "#list1 = []\n",
    "client = OpenAI(\n",
    "    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\"sk-xxx\",\n",
    "    api_key=\"sk-244031ceb83a4722a1abe204942fb30b\", # 如何获取API Key：https://help.aliyun.com/zh/model-studio/developer-reference/get-api-key\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "df_Annotation_auto = pd.read_excel('../中国地方政府工作报告数据库/地级市政府工作报告/preprocessed_data/df_Annotation.xlsx', index_col=0)\n",
    "for index, row in df_Annotation_auto[:10].iterrows():\n",
    "    s1 = row['sentence1']\n",
    "    s2 = row['sentence2']\n",
    "    label = row['label']\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"qwen-plus-latest\", # 模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"name\": \"annotator\", \n",
    "             \"content\": '你是一个 <annotator>, 也是一位在中国政府政策研究方面的专家。 您需要基于 <user>提供的来自中国政府工作报告中的两个代表政策举措的句子和对应的判断，基于五项原则进行校对。判断的label是0代表sentence2相对于sentence1是非创新，1则是创新。原则1，这些句子往往没有主语，以由动词、修饰词和宾语组成；在创新性比较中宾语最为重要，对政策举措的含义有决定性影响，如果两个句子的宾语含义差异较大，或者后一句子的并列宾语明显多于前者且含义超出前一句子的宾语，那么后一句子肯定相对于前者是创新的；其次重要的是直接修饰宾语的修饰词，再次是修饰词的修饰词，依次递减。原则2，句子中的动词是无关的，其含义不影响创新性判断结果，例如sentence1:加强城市化建设; sentence2:重视城市化建设,则sentence2相对于sentence1不是创新，因为\"重视\"和\"加强\"对结果没有影响。原则3，如果前一个政策举措的含义只是后一个政策举措的子集，例如，sentence1:做好民生工作; sentence2:做好民生、防灾工作，这种情况下后一个句子（即sentence2）相对于前一个句子（即sentence1）是创新的。原则4，如果两个句子的内容和结构完全不同，没有直接的可比性，则默认后一句子相对于前一句子是创新的。原则5，如果后一个句子的字数明显少于前一个句子，且核心单词都被前一个句子包含，那么后一个句子相对前一个句子不是创新，例如entence1:加强农村实用人才队伍建设; sentence2:加强人才队伍建设,则sentence2相对于sentence1不是创新。'},\n",
    "            {'role': 'user', 'content': '请指出对sentence2相对于sentence1的错误判断。请注意，label为1则判断结果为创新，label为2则判断结果为非创新'},\n",
    "            {'role': 'user', 'content': '如果某条记录的`label`标注为1但实际上应该是0，或者`label`标注为0但实际上应该是1，这些都属于错误判断。'},\n",
    "            {\"role\": \"user\", \"content\": \"判断这一标注是否正确，并以最终结论输出“这一标注正确”或“这一标注错误”：sentence1:\"+s1+\"; sentence2:\"+s2+\"; lanel:\"+str(label)+\"。\"}\n",
    "            ]\n",
    "    )\n",
    "\n",
    "\n",
    "    print(completion.choices[0].message.content)\n",
    "    #if \"这一标注正确\" in completion.choices[0].message.content:\n",
    "    #    print('yes')\n",
    "    #else:\n",
    "    #    print('no')\n",
    "    #    print()\n",
    "#print(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3737578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"file-fe-a6725d7996d3485ca10c1e17\",\"bytes\":2490580,\"created_at\":1748009193,\"filename\":\"df_Annotation_auto.xlsx\",\"object\":\"file\",\"purpose\":\"file-extract\",\"status\":\"processed\",\"expires_at\":null,\"status_details\":null}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-244031ceb83a4722a1abe204942fb30b\", # 如何获取API Key：https://help.aliyun.com/zh/model-studio/developer-reference/get-api-key\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",  # 填写DashScope服务base_url\n",
    ")\n",
    "\n",
    "file_object = client.files.create(file=Path(\"../中国地方政府工作报告数据库/地级市政府工作报告/preprocessed_data/df_Annotation_auto.xlsx\"), purpose=\"file-extract\")\n",
    "print(file_object.model_dump_json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9280a7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'根据您提供的原则和示例，我将检查表格中的每一项，以确定是否存在错误的创新性判断。以下是详细的分析和错误判断的列表：\\n\\n### 错误判断示例：\\n\\n#### 1. **Sheet1**\\n| Index | Sentence1 | Sentence2 | Label | 评注 |\\n|-------|------------|------------|-------|------|\\n| 0     | 落实职务待遇与业务支出管理规定 | 出台省政府立法工作规定 | 1 | 正确标注。两个句子的主题完全不同，Sentence2涉及的是立法工作，而Sentence1涉及的是职务待遇和业务支出管理。 |\\n| 1     | 推进创新型广东建设大力推进自主创新 | 深化法治建设四级同创 | 1 | 错误标注。两个句子的主题不同，Sentence1强调的是创新和自主创新，而Sentence2强调的是法治建设。应标注为0。 |\\n| 2     | 支持商品房市场更好满足购房者的合理住房需求 | 视同仁满足不同所有制房地产企业的合理融资需求 | 1 | 错误标注。虽然都提到“满足合理需求”，但Sentence1侧重于购房者的需求，而Sentence2侧重于房地产企业的融资需求，属于不同层面的需求。应标注为0。 |\\n| 3     | 企一策推动省属国企战略性重组 | 链一策拓长补短 | 1 | 错误标注。两个句子的主题不同，Sentence1是关于国企重组，而Sentence2是关于供应链的策略。应标注为0。 |\\n| 4     | 高质量谋划实施第二批授权事项清单 | 梳理细化超500项高频民生诉求事项职责清单 | 1 | 正确标注。Sentence2在Sentence1的基础上增加了具体细节，是创新。 |\\n| 5     | 集中供养孤儿基本生活最低养育标准从每人每月1883元提高到1949元 | 集中供养孤儿基本生活保障省定最低标准从每人每月2017元提高到2295元 | 1 | 正确标注。Sentence2在Sentence1的基础上增加了具体细节，是创新。 |\\n| 6     | 其中食用农产品批发市场实现全覆盖快检 | 食用农产品快检超800万批次 | 1 | 正确标注。Sentence2在Sentence1的基础上增加了具体细节，是创新。 |\\n| 7     | 企业退休人员基本养老金增长10% | 高速公路服务区充电基础设施总车位达到小型客车停车位总数的10% | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及退休人员养老金，而Sentence2涉及高速公路服务区的充电设施。应标注为0。 |\\n| 8     | 完善养老保险省级统筹 | 为全省超1700家已备案托育机构统一购买在托婴幼儿意外责任保险 | 1 | 正确标注。Sentence2在Sentence1的基础上增加了具体细节，是创新。 |\\n| 9     | 推动保障群众基本住房需求 | 全面保障特殊困难老年人助餐服务需求 | 1 | 错误标注。两个句子的主题不同，Sentence1涉及的是住房需求，而Sentence2涉及的是老年人助餐服务需求。应标注为0。 |\\n| 10    | 落实国家新的三年棚户区改造攻坚计划 | 提前一年完成十四五规划确定的8.6万户改造计划 | 1 | 正确标注。Sentence2在Sentence1的基础上增加了具体细节，是创新。 |\\n| 11    | 全省所有圩镇达到宜居圩镇标准 | 受援医院基本达到国家县级医院医疗服务能力推荐标准 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是圩镇建设，而Sentence2涉及的是医院医疗服务能力。应标注为0。 |\\n| 12    | 建立涉农资金统筹整合长效机制 | 建立227所县域高中与市域优质高中结对帮扶机制 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是涉农资金统筹，而Sentence2涉及的是高中结对帮扶。应标注为0。 |\\n| 13    | 扩大订单定向医学生招收规模至每年1400名 | 推动工院校招生规模稳定在19万人以 | 1 | 错误标注。两个句子的主题不同，Sentence1涉及的是医学生招收，而Sentence2涉及的是工院校招生规模。应标注为0。 |\\n| 14    | 开展农村社区一站式综合服务示范创建 | 开展新一轮双拥模范城（县）创建 | 1 | 错误标注。两个句子的主题不同，Sentence1涉及的是农村社区服务，而Sentence2涉及的是双拥模范城创建。应标注为0。 |\\n| 15    | 推进节约集约用地示范省 | 推进生育友好省 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是节约集约用地，而Sentence2涉及的是生育友好。应标注为0。 |\\n| 16    | 加强海洋环境监测 | 加强平台企业就业监管监测 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是海洋环境监测，而Sentence2涉及的是平台企业就业监管。应标注为0。 |\\n| 17    | 落实新农保及城镇居民养老保险制度全覆盖财政资金安排 | 推广技培生等制度 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是养老保险制度，而Sentence2涉及的是技培生制度。应标注为0。 |\\n| 18    | 增强人民体质 | 增强青少年体质 | 1 | 正确标注。Sentence2在Sentence1的基础上限定了特定群体，是创新。 |\\n| 19    | 做大做强主流舆论 | 巩固壮大奋进新时代的主流思想舆论 | 1 | 正确标注。Sentence2在Sentence1的基础上增加了具体细节，是创新。 |\\n| 20    | 开展改善消费品供给专项行动 | 全面实施空气质量持续改善行动 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是消费品供给，而Sentence2涉及的是空气质量改善。应标注为0。 |\\n| 21    | 加强红树林及湿地公园保护 | 守护好红树林 | 1 | 错误标注。两个句子的主题不同，Sentence1涉及的是红树林及湿地公园保护，而Sentence2仅涉及红树林保护。应标注为0。 |\\n| 22    | 提升城市综合品质 | 提升海洋生态品质 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是城市综合品质，而Sentence2涉及的是海洋生态品质。应标注为0。 |\\n| 23    | 推进全国旅游综合改革示范区 | 推进琼州海峡一体化高质量发展示范区 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是旅游综合改革，而Sentence2涉及的是琼州海峡一体化发展。应标注为0。 |\\n| 24    | 发展海洋航运 | 推动内河航运与海洋运输贯通 | 1 | 正确标注。Sentence2在Sentence1的基础上增加了具体细节，是创新。 |\\n| 25    | 推动保障群众基本住房需求 | 保障重大项目用海需求 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是住房需求，而Sentence2涉及的是用海需求。应标注为0。 |\\n| 26    | 加快制定全省海洋主体功能区规划 | 出台省海岸带及海洋空间规划 | 1 | 正确标注。Sentence2在Sentence1的基础上增加了具体细节，是创新。 |\\n| 27    | 用好国际友城等外事资源 | 汇聚全球高端资源 | 1 | 正确标注。Sentence2在Sentence1的基础上增加了具体细节，是创新。 |\\n| 28    | 鼓励跨国公司在粤设立总部型企业 | 支持广东企业设立海外销售公司 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是跨国公司设立总部，而Sentence2涉及的是广东企业设立海外销售公司。应标注为0。 |\\n| 29    | 增强国际影响力 | 扩大粤港澳大湾区全球招商大会影响力 | 1 | 正确标注。Sentence2在Sentence1的基础上增加了具体细节，是创新。 |\\n| 30    | 打造消费节庆品牌 | 打造投资广东品牌 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是消费节庆品牌，而Sentence2涉及的是投资品牌。应标注为0。 |\\n| 31    | 推进政务服务事项标准化 | 推动政务服务标准化规范化便利化 | 1 | 正确标注。Sentence2在Sentence1的基础上增加了具体细节，是创新。 |\\n| 32    | 企一策推动省属国企战略性重组 | 企一策推进原创技术策源地 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是国企重组，而Sentence2涉及的是原创技术策源地。应标注为0。 |\\n| 33    | 推广三网融合应用 | 推广数字人民币应用 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是三网融合应用，而Sentence2涉及的是数字人民币应用。应标注为0。 |\\n| 34    | 50%以上的资金用于支持发展养老服务业 | 鼓励保险资金投资养老产业 | 1 | 正确标注。Sentence2在Sentence1的基础上增加了具体细节，是创新。 |\\n| 35    | 推进54个试点县普惠金融村村通 | 做强养老金融 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是普惠金融，而Sentence2涉及的是养老金融。应标注为0。 |\\n| 36    | 培育壮大天使投资人群体 | 培育高质量上市公司群体 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是天使投资人，而Sentence2涉及的是上市公司群体。应标注为0。 |\\n| 37    | 推进财政管理层级扁平化 | 减少供电层级 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是财政管理层级，而Sentence2涉及的是供电层级。应标注为0。 |\\n| 38    | 建立健全促进农民收入较快增长的长效机制 | 健全防范化解拖欠中小企业账款长效机制 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是农民收入增长机制，而Sentence2涉及的是中小企业账款防范机制。应标注为0。 |\\n| 39    | 建立健全依法及时处理群众反映问题的长效机制 | 优化经营主体反映问题快速响应处理机制 | 1 | 正确标注。Sentence2在Sentence1的基础上增加了具体细节，是创新。 |\\n| 40    | 加快建立与基本公共服务均等化相适应的公共财政体系 | 推动各类公共资源交易纳入统一平台体系 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是公共财政体系，而Sentence2涉及的是公共资源交易平台。应标注为0。 |\\n| 41    | 加快城镇污水处理设施及配套管网 | 建设一批地下管网 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是污水处理设施及配套管网，而Sentence2涉及的是地下管网建设。应标注为0。 |\\n| 42    | 构建大湾区城际快速交通网络 | 规划建设雷州半岛输水储水网络 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是交通网络，而Sentence2涉及的是输水储水网络。应标注为0。 |\\n| 43    | 加快珠三角绿色生态水网 | 推进全省水网 | 1 | 错误标注。两个句子的主题不同，Sentence1涉及的是珠三角绿色生态水网，而Sentence2涉及的是全省水网。应标注为0。 |\\n| 44    | 做大做强体育产业 | 推动产业与科技互促双强 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是体育产业，而Sentence2涉及的是产业与科技互促。应标注为0。 |\\n| 45    | 推动高水平高质量普及高中阶段教育 | 高质量推动科学普及 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是高中阶段教育，而Sentence2涉及的是科学普及。应标注为0。 |\\n| 46    | 促进一流高职院校 | 加强高水平职业院校 | 1 | 错误标注。两个句子的主题完全不同，Sentence1涉及的是一流高职院校，而Sentence2涉及的是高水平职业院校。应标注为0。 |\\n| 47    | 探索关键核心技术攻关新型举国体制广东路径 | 探索关键核心技术攻关新型举国体制的广东实践 | 1 | 正确标注。Sentence2在Sentence1的基础上增加了具体细节，是创新。 |\\n| 48    | 制定完善装备制造业发展规划及实施方案 | 制定发布新一批制造业标准体系规划与路线图 | 1 | 正确标注。Sentence2在Sentence1的基础上增加了具体细节，是创新。 |\\n| 49    | 制定实施促进服务业投资发展的政策措施 | 出台促进生产性服务业发展的政策文件 | 1 | 错误标注。两个句子的主题不同，Sentence1涉及的是服务业投资发展，而Sentence2涉及的是生产性服务业发展。应标注为0。 |\\n| 50    | 实施高新技术企业树标提质行动 |  |  | Sentence2为空，无法判断。 |\\n\\n#### 2. **其他表单**\\n由于篇幅较长，这里只展示了部分错误判断，您可以继续按照上述方法检查其他表单中的记录。\\n\\n### 总结：\\n根据上述分析，表格中存在多个错误标注的记录，具体错误标注的原因主要是两个句子的主题不同或Sentence2在Sentence1的基础上增加了具体细节，但并未扩展或改变了核心主题。建议对标注为1但实际上应该是0的记录进行修正，反之亦然。'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-244031ceb83a4722a1abe204942fb30b\",  # 如果您没有配置环境变量，请在此处替换您的API-KEY\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",  # 填写DashScope服务base_url\n",
    ")\n",
    "# 初始化messages列表\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen-long\",\n",
    "    messages=[\n",
    "        {'role': 'system', \"content\": '你是一个 <judger>, 也是一位在中国政策研究方面的专家。你需要基于 <user>提供的excel文件列出其中的错误判断。文件中是标注过的正确分类，其中label是0代表sentence2相对于sentence1是非创新，1则是创新。原则1，这些句子往往没有主语，以由动词、修饰词和宾语组成；在创新性比较中宾语最为重要，对政策举措的含义有决定性影响，如果两个句子的宾语含义差异较大，或者后一句子的并列宾语明显多于前者且含义超出前一句子的宾语，那么后一句子肯定相对于前者是创新的；其次重要的是直接修饰宾语的修饰词，再次是修饰词的修饰词，依次递减。原则2，句子中的动词是无关的，其含义不影响创新性判断结果，例如sentence1:加强城市化建设; sentence2:重视城市化建设,则sentence2相对于sentence1不是创新，因为\"重视\"和\"加强\"对结果没有影响。原则3，如果前一个政策举措的含义只是后一个政策举措的子集，例如，sentence1:做好民生工作; sentence2:做好民生、防灾工作，这种情况下后一个句子（即sentence2）相对于前一个句子（即sentence1）是创新的。原则4，如果两个句子的内容和结构完全不同，没有直接的可比性，则默认后一句子相对于前一句子是创新的。如果后一个句子的字数明显少于前一个句子，且核心单词都被前一个句子包含，那么后一个句子相对前一个句子不是创新，例如entence1:加强农村实用人才队伍建设; sentence2:加强人才队伍建设,则sentence2相对于sentence1不是创新。'},\n",
    "        # 请将 'file-fe-xxx'替换为您实际对话场景所使用的 file-id。\n",
    "        {'role': 'system', 'content': 'fileid://file-fe-a6725d7996d3485ca10c1e17'},\n",
    "        {'role': 'user', 'content': '请指出对sentence2相对于sentence1的错误判断。请注意，label为1则判断结果为创新，label为2则判断结果为非创新'},\n",
    "        {'role': 'user', 'content': '如果某条记录的`label`标注为1但实际上应该是0，或者`label`标注为0但实际上应该是1，这些都属于错误判断。'},\n",
    "        {'role': 'user', 'content': '例如，Sentence1: 落实职务待遇与业务支出管理规定\\n  - Sentence2: 出台省政府立法工作规定 - label: 1, 这个就是正确标注，因为两个句子的主题完全不同，Sentence2涉及的是立法工作，而Sentence1涉及的是职务待遇和业务支出管理'}\n",
    "    ],\n",
    "    stream=True,\n",
    "    stream_options={\"include_usage\": True}\n",
    ")\n",
    "\n",
    "full_content = \"\"\n",
    "for chunk in completion:\n",
    "    if chunk.choices and chunk.choices[0].delta.content:\n",
    "        # 拼接输出内容\n",
    "        full_content += chunk.choices[0].delta.content\n",
    "        #print(chunk.model_dump())\n",
    "\n",
    "print({full_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00106168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
